{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPI2Ang8BPYZeJ6bmEFscH4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## (1) 필요한 모듈 import하기"],"metadata":{"id":"TRpUb22lEmm3"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"pmBEoJFOEYzV","executionInfo":{"status":"ok","timestamp":1714373522145,"user_tz":-540,"elapsed":478,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}}},"outputs":[],"source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report"]},{"cell_type":"markdown","source":["## (2) 데이터 준비\n","load_digits 메서드를 사용합니다."],"metadata":{"id":"-WoNqZqMEihR"}},{"cell_type":"code","source":["data = load_breast_cancer()\n","\n","dir(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VhD5wNx1Eqg8","executionInfo":{"status":"ok","timestamp":1714373525960,"user_tz":-540,"elapsed":3,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"7c0483a8-a2f1-4608-dc59-d1aea50ccbd7"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['DESCR',\n"," 'data',\n"," 'data_module',\n"," 'feature_names',\n"," 'filename',\n"," 'frame',\n"," 'target',\n"," 'target_names']"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## (3) 데이터 이해하기\n","지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n","\n","- Feature Data 지정하기\n","- Label Data 지정하기\n","- Target Names 출력해 보기\n","- 데이터 Describe 해 보기"],"metadata":{"id":"rADf5C0xEuNr"}},{"cell_type":"code","source":["import pandas as pd\n","\n","feature_data = data.data\n","label_data = data.target\n","\n","feature_data.shape, label_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZ7A6fEBExIO","executionInfo":{"status":"ok","timestamp":1714373577577,"user_tz":-540,"elapsed":688,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"89413a3d-930b-4878-884f-9f872e543067"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((569, 30), (569,))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["data.target_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2tgwLY0XE0dw","executionInfo":{"status":"ok","timestamp":1714373577577,"user_tz":-540,"elapsed":3,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"6d2270d3-23b2-47b9-e559-4a7f781cf09b"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['malignant', 'benign'], dtype='<U9')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["print(data.DESCR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgyrRcmFE3Fl","executionInfo":{"status":"ok","timestamp":1714373580258,"user_tz":-540,"elapsed":6,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"906e0005-c04e-4efa-ce9b-2dba89ec21f9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[".. _breast_cancer_dataset:\n","\n","Breast cancer wisconsin (diagnostic) dataset\n","--------------------------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 569\n","\n","    :Number of Attributes: 30 numeric, predictive attributes and the class\n","\n","    :Attribute Information:\n","        - radius (mean of distances from center to points on the perimeter)\n","        - texture (standard deviation of gray-scale values)\n","        - perimeter\n","        - area\n","        - smoothness (local variation in radius lengths)\n","        - compactness (perimeter^2 / area - 1.0)\n","        - concavity (severity of concave portions of the contour)\n","        - concave points (number of concave portions of the contour)\n","        - symmetry\n","        - fractal dimension (\"coastline approximation\" - 1)\n","\n","        The mean, standard error, and \"worst\" or largest (mean of the three\n","        worst/largest values) of these features were computed for each image,\n","        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n","        10 is Radius SE, field 20 is Worst Radius.\n","\n","        - class:\n","                - WDBC-Malignant\n","                - WDBC-Benign\n","\n","    :Summary Statistics:\n","\n","    ===================================== ====== ======\n","                                           Min    Max\n","    ===================================== ====== ======\n","    radius (mean):                        6.981  28.11\n","    texture (mean):                       9.71   39.28\n","    perimeter (mean):                     43.79  188.5\n","    area (mean):                          143.5  2501.0\n","    smoothness (mean):                    0.053  0.163\n","    compactness (mean):                   0.019  0.345\n","    concavity (mean):                     0.0    0.427\n","    concave points (mean):                0.0    0.201\n","    symmetry (mean):                      0.106  0.304\n","    fractal dimension (mean):             0.05   0.097\n","    radius (standard error):              0.112  2.873\n","    texture (standard error):             0.36   4.885\n","    perimeter (standard error):           0.757  21.98\n","    area (standard error):                6.802  542.2\n","    smoothness (standard error):          0.002  0.031\n","    compactness (standard error):         0.002  0.135\n","    concavity (standard error):           0.0    0.396\n","    concave points (standard error):      0.0    0.053\n","    symmetry (standard error):            0.008  0.079\n","    fractal dimension (standard error):   0.001  0.03\n","    radius (worst):                       7.93   36.04\n","    texture (worst):                      12.02  49.54\n","    perimeter (worst):                    50.41  251.2\n","    area (worst):                         185.2  4254.0\n","    smoothness (worst):                   0.071  0.223\n","    compactness (worst):                  0.027  1.058\n","    concavity (worst):                    0.0    1.252\n","    concave points (worst):               0.0    0.291\n","    symmetry (worst):                     0.156  0.664\n","    fractal dimension (worst):            0.055  0.208\n","    ===================================== ====== ======\n","\n","    :Missing Attribute Values: None\n","\n","    :Class Distribution: 212 - Malignant, 357 - Benign\n","\n","    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n","\n","    :Donor: Nick Street\n","\n","    :Date: November, 1995\n","\n","This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n","https://goo.gl/U2Uwz2\n","\n","Features are computed from a digitized image of a fine needle\n","aspirate (FNA) of a breast mass.  They describe\n","characteristics of the cell nuclei present in the image.\n","\n","Separating plane described above was obtained using\n","Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n","Construction Via Linear Programming.\" Proceedings of the 4th\n","Midwest Artificial Intelligence and Cognitive Science Society,\n","pp. 97-101, 1992], a classification method which uses linear\n","programming to construct a decision tree.  Relevant features\n","were selected using an exhaustive search in the space of 1-4\n","features and 1-3 separating planes.\n","\n","The actual linear program used to obtain the separating plane\n","in the 3-dimensional space is that described in:\n","[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n","Programming Discrimination of Two Linearly Inseparable Sets\",\n","Optimization Methods and Software 1, 1992, 23-34].\n","\n","This database is also available through the UW CS ftp server:\n","\n","ftp ftp.cs.wisc.edu\n","cd math-prog/cpo-dataset/machine-learn/WDBC/\n","\n",".. topic:: References\n","\n","   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n","     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n","     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n","     San Jose, CA, 1993.\n","   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n","     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n","     July-August 1995.\n","   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n","     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n","     163-171.\n"]}]},{"cell_type":"markdown","source":["## (4) train, test 데이터 분리\n","모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.  \n","X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요.\n"],"metadata":{"id":"9xu0dQYZOsha"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(feature_data, label_data,\n","                                                    test_size=0.2, stratify=label_data,\n","                                                    random_state=42)\n","\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLVQV7fwQUjz","executionInfo":{"status":"ok","timestamp":1714373595334,"user_tz":-540,"elapsed":286,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"02ab2f4c-0010-4a67-f3a0-d4b9a0ce893e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((455, 30), (114, 30), (455,), (114,))"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## (5) 다양한 모델로 학습시켜보기\n","학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n","\n","- Decision Tree 사용해 보기\n","- Random Forest 사용해 보기\n","- SVM 사용해 보기\n","- SGD Classifier 사용해 보기\n","- Logistic Regression 사용해 보기"],"metadata":{"id":"HYVWnunEOpUk"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","\n","# 학습\n","DecisionTreeClassifier_model = DecisionTreeClassifier()\n","DecisionTreeClassifier_model.fit(X_train, y_train)\n","\n","# 평가\n","y_pred = DecisionTreeClassifier_model.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dBlmOB9LQlKc","executionInfo":{"status":"ok","timestamp":1714373601595,"user_tz":-540,"elapsed":764,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"72e678a7-a935-469e-830a-aaa05f29fee0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.83      0.93      0.88        42\n","           1       0.96      0.89      0.92        72\n","\n","    accuracy                           0.90       114\n","   macro avg       0.89      0.91      0.90       114\n","weighted avg       0.91      0.90      0.90       114\n","\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# 학습\n","RandomForestClassifier_model = RandomForestClassifier()\n","RandomForestClassifier_model.fit(X_train, y_train)\n","\n","# 평가\n","y_pred = RandomForestClassifier_model.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFsUsmr5Sk8h","executionInfo":{"status":"ok","timestamp":1714373602059,"user_tz":-540,"elapsed":465,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"ecbe3fb2-bdb2-4edf-896e-53c9be918e3c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.95      0.93      0.94        42\n","           1       0.96      0.97      0.97        72\n","\n","    accuracy                           0.96       114\n","   macro avg       0.96      0.95      0.95       114\n","weighted avg       0.96      0.96      0.96       114\n","\n"]}]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","# 학습\n","SVC_model = SVC(probability=True)\n","SVC_model.fit(X_train, y_train)\n","\n","# 평가\n","y_pred = SVC_model.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8eNdLHOSIUJ","executionInfo":{"status":"ok","timestamp":1714373602059,"user_tz":-540,"elapsed":7,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"739eab30-27da-4a0f-d9c3-56dba18ffbe4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.95      0.86      0.90        42\n","           1       0.92      0.97      0.95        72\n","\n","    accuracy                           0.93       114\n","   macro avg       0.93      0.91      0.92       114\n","weighted avg       0.93      0.93      0.93       114\n","\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import SGDClassifier\n","\n","# 학습\n","SGDClassifier_model = SGDClassifier()\n","SGDClassifier_model.fit(X_train, y_train)\n","\n","# 평가\n","y_pred = SGDClassifier_model.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9fAs5Z8SMOd","executionInfo":{"status":"ok","timestamp":1714373602059,"user_tz":-540,"elapsed":6,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"74388302-836e-4129-8d60-e60c7d8417b0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.79      0.88        42\n","           1       0.89      1.00      0.94        72\n","\n","    accuracy                           0.92       114\n","   macro avg       0.94      0.89      0.91       114\n","weighted avg       0.93      0.92      0.92       114\n","\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","# 학습\n","LogisticRegression_model = LogisticRegression()\n","LogisticRegression_model.fit(X_train, y_train)\n","\n","# 평가\n","y_pred = LogisticRegression_model.predict(X_test)\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JpXQnOxTS02f","executionInfo":{"status":"ok","timestamp":1714373602059,"user_tz":-540,"elapsed":4,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"b092eb07-6372-4430-be7e-ef74651eca44"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.97      0.90      0.94        42\n","           1       0.95      0.99      0.97        72\n","\n","    accuracy                           0.96       114\n","   macro avg       0.96      0.95      0.95       114\n","weighted avg       0.96      0.96      0.96       114\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}]},{"cell_type":"markdown","source":["- 대체적으로 성능이 좋게 나왔다.\n","  - 그 중 RandomForest, LogisticRegression의 성능이 가장 높게 나왔다."],"metadata":{"id":"E62rAdgBWAF-"}},{"cell_type":"markdown","source":["## (6) 모델을 평가해 보기\n","학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요?  \n","sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요."],"metadata":{"id":"bMbNsyYBOXxN"}},{"cell_type":"markdown","source":["- 발병율을 Recall의 예시로 들 때 자주 사용되는 예로,  \n","  발병 여부를 놓치면 현실에서 큰 문제가 될 수 있기 때문에 Recall을 사용하도록 하는 것이 좋을 것이다."],"metadata":{"id":"2yoF9HXKOZbJ"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","y_pred = RandomForestClassifier_model.predict(X_test)\n","\n","print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")\n","print(f\"Precision Score: {precision_score(y_test, y_pred, average='weighted')}\")\n","print(f\"Recall Score: {recall_score(y_test, y_pred, average='weighted')}\")\n","print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n","print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fde52w6VXtIs","executionInfo":{"status":"ok","timestamp":1714373909012,"user_tz":-540,"elapsed":3,"user":{"displayName":"zlemrdmr","userId":"03737954551669458225"}},"outputId":"3d401b0b-e161-43b3-ad2d-d5c43efd63ca"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Score: 0.956140350877193\n","Precision Score: 0.9560729421281235\n","Recall Score: 0.956140350877193\n","F1 Score: 0.9560273762928301\n","ROC AUC Score: 0.9503968253968255\n"]}]}]}