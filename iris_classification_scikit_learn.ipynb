{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Iris 데이터"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<feature_names>\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "<data>\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "<target_names>\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "<target>\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "\n",
    "print(\"<feature_names>\")\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print(\"<data>\")\n",
    "print(iris_data.data)\n",
    "\n",
    "print(\"<target_names>\")\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print(\"<target>\")\n",
    "print(iris_data.target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection - 학습 데이터와 테스트 데이터\n",
    "\n",
    "- 학습 데이터 셋\n",
    "    - 머신러닝 알고리즘의 학습을 위해 사용\n",
    "    - 데이터의 속성과 결정값(레이블)을 모두 가지고 있음\n",
    "    - 학습 데이터를 기반으로 데이터의 속성과 결정값의 패턴을 인지하고 학습\n",
    "- 테스트 데이터 셋\n",
    "    - 학습된 머신러닝 알고리즘을 테스트\n",
    "    - `학습 데이터 셋과 별개로 제공되어야함`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습 데이터셋, 테스트 데이터셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3)\n",
    "\n",
    "# model 학습\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측치를 테스트셋 타겟과 비교\n",
    "score = dt_clf.predict(X_test)\n",
    "print(f\"예측 정확도: {accuracy_score(y_test, score)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%ㅇ\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 교차 검증 - K-Fold, Stratified K-Fold\n",
    "\n",
    "- 나뉘어진 학습 데이터 셋을 추가로 학습 데이터 셋과 검증 데이터 셋으로 나눈다.-\n",
    "- Stratified K-Fold\n",
    "    - 일반적으로 사용되는 K-Fold 방식\n",
    "    - 불균형한 분포도를 가진 레이블 데이터 셋을 위한 K-Fold 방식\n",
    "        - e.g.) 0: 19900건, 1: 100건\n",
    "    - 학습 데이터셋과 검증 데이터셋이 가지는 레이블 분포도가 유사하도록 검증 데이터를 추출한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-Fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 1번 째\n",
      "train_index: [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test_index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      ">> 2번 째\n",
      "train_index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test_index: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      ">> 3번 째\n",
      "train_index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test_index: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      ">> 4번 째\n",
      "train_index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test_index: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      ">> 5번 째\n",
      "train_index: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "test_index: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "==============================\n",
      "정확도: [1.0, 0.9666666666666667, 0.8666666666666667, 0.9333333333333333, 0.7333333333333333]\n",
      "평균 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kfold.split(iris_data.data):\n",
    "    print(f\">> {i}번 째\")\n",
    "    print(f\"train_index: {train_index}\")\n",
    "    print(f\"test_index: {test_index}\")\n",
    "    i += 1\n",
    "\n",
    "    X_train, X_test = iris_data.data[train_index], iris_data.data[test_index]\n",
    "    y_train, y_test = iris_data.target[train_index], iris_data.target[test_index]\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    score = dt_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, score)\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print(\"==============================\")\n",
    "print(f\"정확도: {cv_accuracy}\")\n",
    "print(f\"평균 정확도: {np.mean(cv_accuracy)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stratified K-Fold\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 1번 째\n",
      "학습셋 데이터 분포: label\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "검증셋 데이터 분포: label\n",
      "0    50\n",
      "Name: count, dtype: int64\n",
      ">> 2번 째\n",
      "학습셋 데이터 분포: label\n",
      "0    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "검증셋 데이터 분포: label\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      ">> 3번 째\n",
      "학습셋 데이터 분포: label\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "검증셋 데이터 분포: label\n",
      "2    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# K-Fold 사용시 데이터 분포 문제\n",
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
    "iris_df[\"label\"] = iris_data.target\n",
    "\n",
    "kfold = KFold(n_splits=3)\n",
    "i = 1\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    print(f\">> {i}번 째\")\n",
    "    print(f'학습셋 데이터 분포: {iris_df[\"label\"][train_index].value_counts()}')\n",
    "    print(f'검증셋 데이터 분포: {iris_df[\"label\"][test_index].value_counts()}')\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 1번 째\n",
      "학습셋 데이터 분포: label\n",
      "2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: count, dtype: int64\n",
      "검증셋 데이터 분포: label\n",
      "0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: count, dtype: int64\n",
      ">> 2번 째\n",
      "학습셋 데이터 분포: label\n",
      "1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "검증셋 데이터 분포: label\n",
      "0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: count, dtype: int64\n",
      ">> 3번 째\n",
      "학습셋 데이터 분포: label\n",
      "0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "검증셋 데이터 분포: label\n",
      "1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: count, dtype: int64\n",
      "==============================\n",
      "정확도: [0.98, 0.92, 1.0]\n",
      "평균 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# StratifiedKFold를 통해 데이터 분포를 고르게 한다\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "cv_accuracy = []\n",
    "i = 1\n",
    "for train_index, test_index in skf.split(iris_df, iris_df[\"label\"]):\n",
    "    print(f\">> {i}번 째\")\n",
    "    print(f'학습셋 데이터 분포: {iris_df[\"label\"][train_index].value_counts()}')\n",
    "    print(f'검증셋 데이터 분포: {iris_df[\"label\"][test_index].value_counts()}')\n",
    "    i += 1\n",
    "\n",
    "    X_train, X_test = iris_data.data[train_index], iris_data.data[test_index]\n",
    "    y_train, y_test = iris_data.target[train_index], iris_data.target[test_index]\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    score = dt_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, score)\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print(\"==============================\")\n",
    "print(f\"정확도: {cv_accuracy}\")\n",
    "print(f\"평균 정확도: {np.mean(cv_accuracy)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### cross_val_score - 교차 검증을 보다 간편하게\n",
    "\n",
    "- KFold의 template 코드를 `cross_val_score를` 통해 단순화 시킨다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: [0.98 0.92 0.98]\n",
      "교차 검증별 정확도: 0.96\n",
      "평균 검증 정확도: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "feature = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(  # StratifiedKFold를 사용\n",
    "    estimator=dt_clf,\n",
    "    X=feature,\n",
    "    y=label,\n",
    "    scoring=\"accuracy\",  # 성능 지표: 정확도\n",
    "    cv=3,  # 교차 검증 세트 수: 3개\n",
    ")\n",
    "\n",
    "## 데이터 확인\n",
    "print(f\"정확도: {scores}\")\n",
    "print(f\"교차 검증별 정확도: {np.mean(scores)}\")\n",
    "print(f\"평균 검증 정확도: {np.round(np.mean(scores), 4)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GridSearchCV\n",
    "\n",
    "- 하이퍼 파라미터를 순차적으로 입력하면서\n",
    "  최적의 파라미터를 도출할 수 있는 방안을 제공한다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       0.000354      0.000201         0.000236        0.000102   \n1       0.000194      0.000002         0.000155        0.000003   \n2       0.000203      0.000004         0.000152        0.000002   \n3       0.000194      0.000005         0.000143        0.000002   \n4       0.000203      0.000005         0.000147        0.000003   \n5       0.000193      0.000004         0.000143        0.000004   \n\n  param_max_depth param_min_samples_split  \\\n0               1                       2   \n1               1                       3   \n2               2                       2   \n3               2                       3   \n4               3                       2   \n5               3                       3   \n\n                                     params  split0_test_score  \\\n0  {'max_depth': 1, 'min_samples_split': 2}              0.675   \n1  {'max_depth': 1, 'min_samples_split': 3}              0.675   \n2  {'max_depth': 2, 'min_samples_split': 2}              0.900   \n3  {'max_depth': 2, 'min_samples_split': 3}              0.900   \n4  {'max_depth': 3, 'min_samples_split': 2}              0.900   \n5  {'max_depth': 3, 'min_samples_split': 3}              0.900   \n\n   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n0              0.675              0.675         0.675000    1.110223e-16   \n1              0.675              0.675         0.675000    1.110223e-16   \n2              0.925              0.900         0.908333    1.178511e-02   \n3              0.925              0.900         0.908333    1.178511e-02   \n4              0.900              0.900         0.900000    0.000000e+00   \n5              1.000              0.900         0.933333    4.714045e-02   \n\n   rank_test_score  split0_train_score  split1_train_score  \\\n0                5              0.7000              0.6875   \n1                5              0.7000              0.6875   \n2                2              0.9875              0.9625   \n3                2              0.9875              0.9625   \n4                4              0.9875              0.9750   \n5                1              0.9875              0.9750   \n\n   split2_train_score  mean_train_score  std_train_score  \n0              0.6875          0.691667         0.005893  \n1              0.6875          0.691667         0.005893  \n2              0.9875          0.979167         0.011785  \n3              0.9875          0.979167         0.011785  \n4              0.9875          0.983333         0.005893  \n5              0.9875          0.983333         0.005893  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_max_depth</th>\n      <th>param_min_samples_split</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n      <th>split0_train_score</th>\n      <th>split1_train_score</th>\n      <th>split2_train_score</th>\n      <th>mean_train_score</th>\n      <th>std_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000354</td>\n      <td>0.000201</td>\n      <td>0.000236</td>\n      <td>0.000102</td>\n      <td>1</td>\n      <td>2</td>\n      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n      <td>0.675</td>\n      <td>0.675</td>\n      <td>0.675</td>\n      <td>0.675000</td>\n      <td>1.110223e-16</td>\n      <td>5</td>\n      <td>0.7000</td>\n      <td>0.6875</td>\n      <td>0.6875</td>\n      <td>0.691667</td>\n      <td>0.005893</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000194</td>\n      <td>0.000002</td>\n      <td>0.000155</td>\n      <td>0.000003</td>\n      <td>1</td>\n      <td>3</td>\n      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n      <td>0.675</td>\n      <td>0.675</td>\n      <td>0.675</td>\n      <td>0.675000</td>\n      <td>1.110223e-16</td>\n      <td>5</td>\n      <td>0.7000</td>\n      <td>0.6875</td>\n      <td>0.6875</td>\n      <td>0.691667</td>\n      <td>0.005893</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000203</td>\n      <td>0.000004</td>\n      <td>0.000152</td>\n      <td>0.000002</td>\n      <td>2</td>\n      <td>2</td>\n      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n      <td>0.900</td>\n      <td>0.925</td>\n      <td>0.900</td>\n      <td>0.908333</td>\n      <td>1.178511e-02</td>\n      <td>2</td>\n      <td>0.9875</td>\n      <td>0.9625</td>\n      <td>0.9875</td>\n      <td>0.979167</td>\n      <td>0.011785</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000194</td>\n      <td>0.000005</td>\n      <td>0.000143</td>\n      <td>0.000002</td>\n      <td>2</td>\n      <td>3</td>\n      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n      <td>0.900</td>\n      <td>0.925</td>\n      <td>0.900</td>\n      <td>0.908333</td>\n      <td>1.178511e-02</td>\n      <td>2</td>\n      <td>0.9875</td>\n      <td>0.9625</td>\n      <td>0.9875</td>\n      <td>0.979167</td>\n      <td>0.011785</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000203</td>\n      <td>0.000005</td>\n      <td>0.000147</td>\n      <td>0.000003</td>\n      <td>3</td>\n      <td>2</td>\n      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n      <td>0.900</td>\n      <td>0.900</td>\n      <td>0.900</td>\n      <td>0.900000</td>\n      <td>0.000000e+00</td>\n      <td>4</td>\n      <td>0.9875</td>\n      <td>0.9750</td>\n      <td>0.9875</td>\n      <td>0.983333</td>\n      <td>0.005893</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000193</td>\n      <td>0.000004</td>\n      <td>0.000143</td>\n      <td>0.000004</td>\n      <td>3</td>\n      <td>3</td>\n      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n      <td>0.900</td>\n      <td>1.000</td>\n      <td>0.900</td>\n      <td>0.933333</td>\n      <td>4.714045e-02</td>\n      <td>1</td>\n      <td>0.9875</td>\n      <td>0.9750</td>\n      <td>0.9875</td>\n      <td>0.983333</td>\n      <td>0.005893</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 파라미터: {'max_depth': 3, 'min_samples_split': 3}\n",
      "최고 정확도: 0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2)\n",
    "\n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_grid={\n",
    "        \"max_depth\": [1, 2, 3],\n",
    "        \"min_samples_split\": [2, 3],\n",
    "    },\n",
    "    cv=3,\n",
    "    refit=True,  # 가장 좋은 파라미터 기준으로 재학습 실행 여부\n",
    "    return_train_score=True,\n",
    ")\n",
    "# 학습 데이터 셋으로 하이퍼 파라미터들을 순차적으로 학습 및 평가\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "scores_df = pd.DataFrame(grid_dt.cv_results_)\n",
    "display(scores_df)\n",
    "print(f\"최적 파라미터: {grid_dt.best_params_}\")\n",
    "print(f\"최고 정확도: {grid_dt.best_score_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# `refit=True` 옵션을 준 경우 GridSearchCV 자체적으로 predict를 수행할 수 있음\n",
    "y_pred = grid_dt.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)\n",
    "\n",
    "# 혹은 best_estimator_를 사용할 수 있음\n",
    "y_pred = grid_dt.best_estimator_.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
