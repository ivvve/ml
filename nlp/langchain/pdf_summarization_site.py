from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

def process_text(text):
    # textë¥¼ chunkë¡œ ë¶„í• 
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1_000,
        chunk_overlap=200,
        length_function=len,
    )
    chunks = text_splitter.split_text(text)

    # ë²¡í„° ë³€í™˜
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    documents = FAISS.from_texts(chunks, embeddings)
    return documents

import streamlit as st
from PyPDF2 import PdfReader # pip install PyPDF2
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains.question_answering import load_qa_chain

import os

def main():
    assert os.environ.get("GOOGLE_API_KEY")

    st.title("ğŸ“ PDF ìš”ì•½")
    st.divider()

    pdf = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”", type="pdf")

    if not pdf:
        return

    pdf_reader = PdfReader(pdf)
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    
    # chunkë¡œ ë¶„í• í•˜ì—¬ vectorí™”ëœ ë°ì´í„°
    documents = process_text(text)
    query = "ì—…ë¡œë“œëœ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ì•½ 3~5 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”."
    docs = documents.similarity_search(query)

    llm = ChatGoogleGenerativeAI(model="gemini-pro",
                                 temperature=0.1)
    chain = load_qa_chain(llm, chain_type="stuff", verbose=True)
    response = chain.run(input_documents=docs, question=query)

    st.subheader("-- ìš”ì•½ ê²°ê³¼ --")
    st.write(response)

if __name__ == "__main__":
    main()
