{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카메라를 홍보하기 위한 좋은 문구를 추천해줘.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"{product}를 홍보하기 위한 좋은 문구를 추천해줘.\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"product\"],\n",
    ")\n",
    "prompt.format(product=\"카메라\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm1 = ChatOpenAI(temperature=0, # 창의성 0으로 설정\n",
    "                  model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "prompt = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "llm1.predict(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅페이스 hub 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm2 = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\",\n",
    "               model_kwargs={\"temperature\": 0.8, \"max_length\": 512})\n",
    "prompt = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "llm2.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini AI chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='강아지', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-091066e0-3372-419f-8b87-e6dc0ecb1e01-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm3 = ChatGoogleGenerativeAI(model=\"gemini-pro\", \n",
    "                              temperature=0)\n",
    "prompt = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "llm3.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.model_laboratory import ModelLaboratory\n",
    "\n",
    "model_lab = ModelLaboratory.from_llms([llm1, llm2, llm3])\n",
    "model_lab.compare(\"대한민국의 가을은 몇 월부터 몇 월까지야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력 파서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0, \n",
    "#                  max_tokens=2048, \n",
    "#                  model_name=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0)\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions() # 출력 형식 지정\n",
    "prompt = PromptTemplate(\n",
    "    template=\"7개의 팀을 보여줘 {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}, # <= 출력 형식 전달\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeongcheol/anaconda3/envs/kaggle/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두산 베어스, 삼성 라이온즈, LG 트윈스, KIA 타이거즈, 롯데 자이언츠, 한화 이글스, 키움 히어로즈\n",
      "['두산 베어스', '삼성 라이온즈', 'LG 트윈스', 'KIA 타이거즈', '롯데 자이언츠', '한화 이글스', '키움 히어로즈']\n"
     ]
    }
   ],
   "source": [
    "query = \"한국의 야구팀은?\"\n",
    "\n",
    "output = llm.predict(text=prompt.format(subject=query))\n",
    "parsed_result = output_parser.parse(output)\n",
    "\n",
    "print(output)\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1    The Fence \\n \\nTom Sawyer lived with his aunt because his mother and \\nfather were dead. T'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./data/The_Adventures_of_Tom_Sawyer.pdf\")\n",
    "document = loader.load()\n",
    "\n",
    "# 5 페이지에서 100 글자 읽어오기\n",
    "document[5].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "text = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "text_embedding # vector로 바뀌게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1e3a480b854b87883c8cd49e673e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b65e0a240014960bf97294423bf38dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e88133a7e5e4facad1939d442f80004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8824ec56b21d4b26a20fb4c1481f7ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3858823f29f948a8ac741d22a44ed909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f239ce1d991842319a34ee26eec9a4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58cb2496ccd4f098247901299fb3c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92670c92be514ded807c7689741cb0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82dc145ee394066a14a5bffeb71e53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494cb5095a724fa0875a275277c83916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14349e084fdd4874abf2313d2490e691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013278813101351261, 0.07225915789604187, 0.09263098984956741, -0.003979590255767107, 0.0015617485623806715, -0.10306371748447418, 0.10929881036281586, 0.055662062019109726, -0.03116741217672825, -0.0502031184732914, 0.08312951773405075, -0.008924420922994614, 0.0950632393360138, -0.06980786472558975, 0.03955896198749542, -0.10899192094802856, 0.049438703805208206, 0.037364762276411057, -0.1240922138094902, -0.0033154746051877737, 0.04840953275561333, -0.031085100024938583, 0.008206969127058983, 0.06326048076152802, -0.06804244965314865, -0.010208186693489552, 0.004926975350826979, -0.014940351247787476, -0.0014766291715204716, -0.006598887965083122, -0.040159545838832855, 0.08289805799722672, 0.014144709333777428, -0.011793539859354496, -0.09415140002965927, 0.0021563491318374872, -0.019053086638450623, -0.03773898631334305, -0.003271099179983139, 0.046856120228767395, -0.1811162233352661, -0.11718787252902985, 0.03504839166998863, -0.06848108023405075, 0.06553437560796738, 0.03522864729166031, -0.04974852129817009, -0.12612947821617126, -0.07845969498157501, 0.004257929045706987, -0.10124041140079498, -0.025174010545015335, 0.028697680681943893, -0.09642510116100311, 0.004547140095382929, 0.013642469421029091, -0.07578512281179428, 0.0015168151585385203, 0.012643786147236824, 0.03935788944363594, 0.02581172063946724, 0.010000519454479218, 0.003953085746616125, 0.1066179946064949, 0.07008880376815796, 0.003821332473307848, -0.028669068589806557, -0.04812316969037056, 0.023298710584640503, -0.07286635786294937, 0.10862239450216293, -0.0030020177364349365, 0.045723944902420044, 0.028517721220850945, -0.06160316988825798, -0.04397081211209297, -0.04367738589644432, -0.016793910413980484, -0.024261243641376495, -0.0081806480884552, 0.027305398136377335, 0.0623050220310688, -0.026362726464867592, 0.045845720916986465, -0.03654494509100914, -0.011483710259199142, -0.007790843024849892, -0.011519081890583038, -0.1322515457868576, 0.06266410648822784, 0.0849028080701828, 0.13822096586227417, -0.06200697645545006, 0.011805293150246143, -0.0674382820725441, 0.03455714136362076, -0.027235448360443115, -0.045849066227674484, 0.017875799909234047, 0.01934959925711155, -0.010784833692014217, 0.0567726194858551, -0.003138235304504633, 0.059460997581481934, -0.05615430697798729, -0.04563063010573387, -0.0117256548255682, -0.07855498790740967, 0.031177092343568802, 0.044499997049570084, -0.058531295508146286, -0.07459667325019836, -0.1116492822766304, -0.08641170710325241, -0.0022324067540466785, -0.05567562207579613, -0.029581371694803238, -0.019913243129849434, 0.020892420783638954, 4.4848180550616235e-05, 0.01631333865225315, -0.01923966407775879, 0.007343337405472994, -0.056915123015642166, -0.06024607643485069, -0.06726784259080887, 0.056991398334503174, 5.7571209690544054e-33, -0.1167159453034401, -0.04787522926926613, 0.024304546415805817, -0.007873361930251122, -0.07164964079856873, -0.04347354546189308, -0.0005882375407963991, -0.012201094068586826, -0.01013378519564867, 0.012090019881725311, -0.013181958347558975, 0.013157044537365437, -0.11160201579332352, 0.022420009598135948, 0.079297736287117, 0.020015913993120193, 0.010653294622898102, 0.018925663083791733, -0.07727376371622086, 0.06650302559137344, -0.01903139427304268, 0.04687986522912979, 0.04418344050645828, -0.012243665754795074, 0.017359554767608643, -0.036382876336574554, 0.036862920969724655, -0.05764244869351387, -0.08014419674873352, 0.05139586329460144, 0.0679701715707779, -0.06613985449075699, 0.015986917540431023, -0.017422813922166824, -0.08709702640771866, -0.04842481017112732, -0.031398605555295944, -0.018943235278129578, 0.03598484769463539, -0.015173965133726597, -0.056677527725696564, -0.016627753153443336, 0.002675804542377591, 0.07279299199581146, -0.01660853624343872, 0.15623927116394043, 0.02005375176668167, -0.003648974234238267, -0.04288453608751297, -0.010872350074350834, -0.005499897059053183, 0.04295511916279793, 0.006219576578587294, 0.01831131987273693, 0.061551131308078766, 0.049766331911087036, 0.0775165855884552, -0.050673216581344604, -0.09273554384708405, 0.04337533563375473, -0.025706477463245392, 0.06924054026603699, -0.016224317252635956, -0.03552992269396782, 0.03515232354402542, 0.02752411551773548, -0.03159337118268013, 0.00213211914524436, 0.06902910768985748, -0.028676923364400864, 0.007580752484500408, -0.029038479551672935, -0.05763727053999901, 0.08411041647195816, -0.051065266132354736, -0.018209047615528107, -0.03221713751554489, 0.008495703339576721, -0.023271307349205017, 0.10360081493854523, -0.04715126007795334, 0.05071769282221794, -0.019967306405305862, -0.08733563125133514, 0.04307279363274574, 0.04250314086675644, 0.061885323375463486, -0.029018115252256393, 0.057500045746564865, 0.0996256098151207, 0.0031136353500187397, -0.021080030128359795, -0.02131306566298008, 0.009604335762560368, -0.010661456733942032, -1.10823175591587e-32, 0.02246195077896118, 0.0501403734087944, -0.04363615810871124, 0.043190911412239075, 0.014806084334850311, -0.02212906815111637, -0.035336025059223175, -0.01296602375805378, 0.04126866161823273, 0.07568332552909851, -0.022778186947107315, 0.0044646961614489555, -0.0020231592934578657, 0.008317687548696995, 0.012391253374516964, 0.02345789223909378, -0.004618572071194649, 0.016717521473765373, -0.03969214856624603, 0.07550635933876038, -0.02475336380302906, 0.0006305371643975377, -0.02586473524570465, 0.02483491599559784, -0.06750302761793137, -0.028255293145775795, -0.02914685197174549, 0.0050552235916256905, -0.04198852926492691, -0.03363959863781929, 0.04718655347824097, -0.09567124396562576, 0.05342177674174309, 0.07293441146612167, 0.05589480325579643, -0.11131346970796585, -0.032456450164318085, -0.06448210775852203, -0.007085256744176149, -0.055354923009872437, -0.0018305196426808834, -0.03703378140926361, 0.06931706517934799, -0.0663718655705452, -0.01175348088145256, -0.060574281960725784, -0.04211129620671272, -0.05767347291111946, 0.01326304767280817, -0.07821604609489441, 0.10719431936740875, 0.013944954611361027, -0.0018788917222991586, -0.06151437386870384, 0.07397802174091339, 0.0016911483835428953, 0.007283973041921854, 0.029222456738352776, -0.015497134998440742, -0.026651587337255478, 0.040174491703510284, -0.03012089990079403, -0.017243949696421623, 0.08458483964204788, -0.0727551281452179, 0.02476680278778076, 0.04224059730768204, -0.07882049679756165, -0.02020173892378807, -0.05122325196862221, 0.02502266876399517, 0.010713660158216953, 0.09445089846849442, 0.0012765764258801937, -0.11785262078046799, -0.023612238466739655, -0.006602663546800613, -0.00565137667581439, 0.0248859990388155, -0.007404394913464785, -0.07830582559108734, 0.04434233903884888, -0.004738562274724245, -0.030357224866747856, -0.09630072116851807, -0.07722237706184387, -0.01173744723200798, -0.012655752710998058, -0.0205518901348114, -0.03310268372297287, -0.0069870357401669025, 0.06579409539699554, -0.06467685103416443, 0.016722766682505608, 0.025865012779831886, -6.747298186837725e-08, 0.014355814084410667, -0.10713933408260345, 0.059572938829660416, 0.014457129873335361, 0.024237249046564102, 0.0008713105344213545, 0.04152451828122139, 0.020225942134857178, -0.02323179505765438, -0.001036931062117219, 0.06980491429567337, 0.03986063227057457, -0.0910438671708107, 0.07905731350183487, -0.055060215294361115, -0.09717672318220139, 0.02966943196952343, 0.08205384016036987, 0.015298718586564064, -0.029271209612488747, 0.03958222642540932, -0.033702265471220016, -0.05486965924501419, 0.016918690875172615, -0.024195004254579544, 0.017249729484319687, -0.012048192322254181, -0.026754572987556458, 0.005114174913614988, -0.043591778725385666, -0.003882606979459524, -0.03072366677224636, 0.0005513802170753479, -0.04155451059341431, 0.04173419252038002, -0.02271139807999134, -0.051652692258358, 0.0019998897332698107, -0.030036775395274162, 0.013122675940394402, -0.036142971366643906, -0.09906813502311707, 0.057611413300037384, 0.03177979215979576, 0.06513634324073792, -0.025864534080028534, 0.02020489051938057, -0.031005851924419403, -0.035835642367601395, 0.03948349878191948, -0.026185961440205574, -0.017085567116737366, 0.0013755097752436996, -0.020843781530857086, 0.020826363936066628, 0.03732387721538544, 0.017785869538784027, 0.031677745282649994, -0.03965364396572113, 0.010524062439799309, 0.016324682161211967, 0.041192613542079926, 0.043899793177843094, 0.011871975846588612]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "text = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.051796567,\n",
       " 0.0012831187,\n",
       " -0.061716117,\n",
       " -0.019468084,\n",
       " 0.06413684,\n",
       " -0.0029500334,\n",
       " -0.005008839,\n",
       " -0.035008013,\n",
       " 0.028707424,\n",
       " 0.040209964,\n",
       " -0.044103753,\n",
       " 0.03324932,\n",
       " -0.022462213,\n",
       " 0.024522226,\n",
       " -0.018280877,\n",
       " -0.05598827,\n",
       " 0.02232451,\n",
       " 0.011281302,\n",
       " 0.0487188,\n",
       " -0.0057292846,\n",
       " 0.006892528,\n",
       " 0.012051351,\n",
       " -0.01913069,\n",
       " 0.0087253805,\n",
       " 0.017330216,\n",
       " -0.023209892,\n",
       " 0.013236641,\n",
       " -0.0348444,\n",
       " -0.039317638,\n",
       " -0.0023582242,\n",
       " -0.02595366,\n",
       " 0.03395715,\n",
       " -0.07083947,\n",
       " 0.0037453463,\n",
       " 0.0010758026,\n",
       " -0.051002707,\n",
       " -0.026740054,\n",
       " 0.013611408,\n",
       " 0.017121235,\n",
       " 0.0035125078,\n",
       " 0.03222491,\n",
       " -0.043666262,\n",
       " -0.04705308,\n",
       " 0.018607069,\n",
       " -0.03519223,\n",
       " 0.03237643,\n",
       " -0.028474594,\n",
       " -0.004485306,\n",
       " 0.013898104,\n",
       " -0.040032804,\n",
       " 0.025934827,\n",
       " 0.022557713,\n",
       " 0.0738044,\n",
       " -0.02703792,\n",
       " -0.018603696,\n",
       " -0.028168276,\n",
       " 0.041772258,\n",
       " -0.0024704982,\n",
       " 0.022514986,\n",
       " 0.035138723,\n",
       " -0.010367743,\n",
       " 0.010792714,\n",
       " 0.029123085,\n",
       " 0.023394154,\n",
       " -0.041342124,\n",
       " -0.043447718,\n",
       " -0.03078189,\n",
       " 0.012571238,\n",
       " 0.04819209,\n",
       " 0.011711805,\n",
       " -0.012932111,\n",
       " -0.021566788,\n",
       " 0.057924584,\n",
       " 0.0021628654,\n",
       " -0.00513147,\n",
       " -0.15001895,\n",
       " -0.022792164,\n",
       " 0.059724834,\n",
       " 0.023374323,\n",
       " -0.026776234,\n",
       " 0.010057019,\n",
       " -0.05300419,\n",
       " -0.08444848,\n",
       " -0.029588265,\n",
       " -0.05134269,\n",
       " 0.009934969,\n",
       " -0.039623577,\n",
       " -0.0059712734,\n",
       " 0.029143782,\n",
       " 0.0241794,\n",
       " -0.011700513,\n",
       " -0.00492326,\n",
       " 0.05744477,\n",
       " -0.05324061,\n",
       " -0.0050758794,\n",
       " 0.091002606,\n",
       " -0.046796896,\n",
       " -0.025240581,\n",
       " 0.032720298,\n",
       " -0.014004652,\n",
       " -0.0056529976,\n",
       " -0.03836864,\n",
       " -0.07112231,\n",
       " 0.01881613,\n",
       " 0.048366014,\n",
       " 0.004118049,\n",
       " 0.020923985,\n",
       " 0.038247295,\n",
       " 0.0017486741,\n",
       " 0.02379489,\n",
       " -0.042056154,\n",
       " 0.0048464243,\n",
       " 0.02760245,\n",
       " 0.014035984,\n",
       " 0.02718944,\n",
       " -0.053019516,\n",
       " 0.01441589,\n",
       " 0.08328995,\n",
       " 0.071181655,\n",
       " 0.026643546,\n",
       " 0.027020218,\n",
       " -0.0048605036,\n",
       " 0.052383512,\n",
       " -0.014749807,\n",
       " 0.02115207,\n",
       " 0.001256675,\n",
       " -0.035867084,\n",
       " 0.03660077,\n",
       " 0.031408522,\n",
       " -0.002288285,\n",
       " -0.026928186,\n",
       " -0.04520444,\n",
       " -0.053407453,\n",
       " 0.01503437,\n",
       " 0.05722922,\n",
       " 0.06269592,\n",
       " 0.023814892,\n",
       " -0.03110227,\n",
       " 0.03060401,\n",
       " -0.0032271731,\n",
       " 0.008782714,\n",
       " 0.019620584,\n",
       " -0.008764351,\n",
       " 0.028910046,\n",
       " -0.0017877861,\n",
       " 0.083550975,\n",
       " -0.07557845,\n",
       " -0.0031437997,\n",
       " 0.08922876,\n",
       " -0.037037067,\n",
       " -0.033225372,\n",
       " -0.015979152,\n",
       " -0.063884474,\n",
       " -0.018770583,\n",
       " 0.05881363,\n",
       " -0.008476631,\n",
       " -0.050209053,\n",
       " 0.020030158,\n",
       " -0.010382088,\n",
       " 0.019498609,\n",
       " 0.02396261,\n",
       " 0.02500654,\n",
       " 0.017275866,\n",
       " 0.03139147,\n",
       " 0.008002242,\n",
       " -0.025855057,\n",
       " -0.018829497,\n",
       " -0.02062406,\n",
       " 0.008161541,\n",
       " 0.035468053,\n",
       " -0.03520448,\n",
       " 0.035756495,\n",
       " -0.06263965,\n",
       " -0.03939752,\n",
       " -0.030534714,\n",
       " -0.03821503,\n",
       " 0.02558864,\n",
       " -0.001838919,\n",
       " -0.039597627,\n",
       " -0.0033501796,\n",
       " 0.016566489,\n",
       " -0.04813541,\n",
       " 0.021348048,\n",
       " 0.052229248,\n",
       " 0.019748803,\n",
       " -0.06711602,\n",
       " 0.07223124,\n",
       " 0.01653994,\n",
       " -0.01894213,\n",
       " 0.006236583,\n",
       " -0.010197271,\n",
       " -0.014309234,\n",
       " -0.05644532,\n",
       " -0.047029436,\n",
       " -0.024103703,\n",
       " 0.036665257,\n",
       " 0.020306828,\n",
       " 0.008215103,\n",
       " 0.010398422,\n",
       " -0.031168958,\n",
       " 0.0023070192,\n",
       " 0.044567477,\n",
       " -0.019928474,\n",
       " -0.008036782,\n",
       " 0.03663707,\n",
       " -0.023646446,\n",
       " 0.055958554,\n",
       " -0.04630222,\n",
       " -0.05097279,\n",
       " 0.022260178,\n",
       " -0.028462058,\n",
       " 0.039134428,\n",
       " -0.05100706,\n",
       " -0.005126639,\n",
       " 0.015169048,\n",
       " -0.034853145,\n",
       " 0.020994736,\n",
       " 0.026979947,\n",
       " 0.03225704,\n",
       " -0.020168591,\n",
       " -0.013184656,\n",
       " 0.019135049,\n",
       " -0.036287077,\n",
       " 0.0012873287,\n",
       " -0.008574175,\n",
       " 0.057192028,\n",
       " -0.012260208,\n",
       " 0.016922837,\n",
       " 0.019937567,\n",
       " -0.021242904,\n",
       " 0.010230871,\n",
       " 0.06828051,\n",
       " 0.0502101,\n",
       " 0.0005828163,\n",
       " 0.07341333,\n",
       " -0.025329448,\n",
       " 0.019705988,\n",
       " 0.027947236,\n",
       " 0.025592225,\n",
       " 0.01293535,\n",
       " -0.056317355,\n",
       " 0.050631903,\n",
       " 0.033271205,\n",
       " 0.038867578,\n",
       " -0.054105196,\n",
       " -0.05335826,\n",
       " -0.014806932,\n",
       " 0.06069907,\n",
       " 0.015156481,\n",
       " 0.036676202,\n",
       " 0.0038543444,\n",
       " -0.06630029,\n",
       " -0.025485164,\n",
       " -0.0005291057,\n",
       " -0.10131989,\n",
       " 0.021128869,\n",
       " -0.055534318,\n",
       " 0.033444904,\n",
       " -0.016609073,\n",
       " 0.01872138,\n",
       " 0.06274507,\n",
       " -0.0065082605,\n",
       " -0.0011382399,\n",
       " -0.0342519,\n",
       " 0.007624829,\n",
       " -0.015031884,\n",
       " 0.018806826,\n",
       " -0.07299328,\n",
       " 0.018492088,\n",
       " -0.014842419,\n",
       " 0.015755292,\n",
       " -0.030319273,\n",
       " 0.03232328,\n",
       " -0.0004685305,\n",
       " -0.0031442977,\n",
       " 0.010412896,\n",
       " 0.0002593713,\n",
       " 0.08581287,\n",
       " 0.007287478,\n",
       " -0.045417402,\n",
       " 0.026500938,\n",
       " 0.005365611,\n",
       " 0.019727685,\n",
       " -0.03020679,\n",
       " 0.014481516,\n",
       " -0.0109149115,\n",
       " -0.08447773,\n",
       " -0.052029587,\n",
       " 0.03601113,\n",
       " -0.05427096,\n",
       " -0.03164062,\n",
       " -0.03724779,\n",
       " 0.03350143,\n",
       " -0.028602289,\n",
       " -0.011530229,\n",
       " 0.024389863,\n",
       " -0.0117430445,\n",
       " 0.030042276,\n",
       " 0.010209451,\n",
       " -0.04481948,\n",
       " -0.004833715,\n",
       " -0.062159363,\n",
       " 0.030296411,\n",
       " -0.0679618,\n",
       " -0.006852198,\n",
       " 0.020138392,\n",
       " -0.026571093,\n",
       " -0.05159739,\n",
       " 0.028695665,\n",
       " 0.01814173,\n",
       " -0.010269963,\n",
       " 0.029677477,\n",
       " -0.0499096,\n",
       " -0.017010203,\n",
       " 0.023697903,\n",
       " 0.01849081,\n",
       " -0.024205571,\n",
       " 0.02818877,\n",
       " -0.005933582,\n",
       " 0.030682493,\n",
       " 0.00045580495,\n",
       " 0.04631053,\n",
       " 0.02511941,\n",
       " -0.0037893874,\n",
       " -0.0008482816,\n",
       " 0.04288016,\n",
       " 0.01042523,\n",
       " 0.0016095507,\n",
       " -0.025262339,\n",
       " 0.0046824077,\n",
       " -0.03758374,\n",
       " 0.015064871,\n",
       " -0.05895541,\n",
       " -0.005349019,\n",
       " -0.014072504,\n",
       " 0.060850658,\n",
       " -0.10753842,\n",
       " -0.014687005,\n",
       " -0.060028635,\n",
       " 0.0022731437,\n",
       " 0.013069568,\n",
       " 0.008121787,\n",
       " -0.048469502,\n",
       " -0.059390686,\n",
       " 0.008418856,\n",
       " -0.024349747,\n",
       " -0.06340498,\n",
       " 0.04870194,\n",
       " 0.05328321,\n",
       " 0.040612873,\n",
       " -0.005879515,\n",
       " 0.090408295,\n",
       " -0.0042601465,\n",
       " 0.035587266,\n",
       " -0.0150842285,\n",
       " -0.033504345,\n",
       " 0.027175734,\n",
       " -0.0428464,\n",
       " -0.0079923365,\n",
       " -0.038354427,\n",
       " 0.026380502,\n",
       " 0.029848041,\n",
       " -0.015001702,\n",
       " -0.022351949,\n",
       " -0.0047928453,\n",
       " -0.011792049,\n",
       " -0.0048096543,\n",
       " 0.004646694,\n",
       " -0.010607205,\n",
       " 0.0627098,\n",
       " -0.011319552,\n",
       " -0.02609435,\n",
       " 0.044313826,\n",
       " -0.060490075,\n",
       " -0.0042056506,\n",
       " -0.0046796515,\n",
       " -0.045567874,\n",
       " -0.039815973,\n",
       " 0.04500854,\n",
       " -0.011350837,\n",
       " -0.011395543,\n",
       " 0.0031359273,\n",
       " 0.04257448,\n",
       " 0.020049974,\n",
       " 0.038015895,\n",
       " 0.005233872,\n",
       " 0.043670952,\n",
       " 0.03235355,\n",
       " -0.012476309,\n",
       " 0.025649782,\n",
       " -0.028467003,\n",
       " 0.044248216,\n",
       " 0.04960729,\n",
       " 0.0026407703,\n",
       " 0.029657071,\n",
       " -0.02272182,\n",
       " -0.011050208,\n",
       " -0.0636556,\n",
       " 0.024185453,\n",
       " 0.044519115,\n",
       " -0.026497606,\n",
       " -0.07260944,\n",
       " -0.047375154,\n",
       " -0.00932954,\n",
       " -0.060895454,\n",
       " 0.01490591,\n",
       " 0.028184745,\n",
       " -0.008380271,\n",
       " -0.06394479,\n",
       " -0.036271416,\n",
       " 0.015756913,\n",
       " 0.009207241,\n",
       " 0.0049439506,\n",
       " -0.0917124,\n",
       " -0.056968722,\n",
       " -0.037607253,\n",
       " 0.062343456,\n",
       " -0.015494853,\n",
       " -0.014572862,\n",
       " 0.04397413,\n",
       " -0.042011615,\n",
       " -0.0009289555,\n",
       " -0.0121562295,\n",
       " 0.0058499216,\n",
       " -0.08018023,\n",
       " -0.010840631,\n",
       " 0.021399504,\n",
       " 0.00909025,\n",
       " -0.01325319,\n",
       " -0.00555459,\n",
       " 0.031071186,\n",
       " 0.018761313,\n",
       " -0.025593026,\n",
       " -0.028209107,\n",
       " 0.0018005674,\n",
       " -0.04692663,\n",
       " -0.016590916,\n",
       " 0.048565745,\n",
       " 0.0054260683,\n",
       " -0.02763199,\n",
       " 0.033123527,\n",
       " -0.045471106,\n",
       " 0.008270259,\n",
       " 0.0011544689,\n",
       " -0.020278716,\n",
       " -0.022517806,\n",
       " 0.0042737764,\n",
       " -0.0060603307,\n",
       " 0.011579865,\n",
       " -0.081049174,\n",
       " 0.040374137,\n",
       " -0.073977575,\n",
       " -0.04756776,\n",
       " -0.06413984,\n",
       " -0.08649375,\n",
       " -0.0048803603,\n",
       " 0.012846697,\n",
       " 0.047135137,\n",
       " -0.030634468,\n",
       " 0.016845359,\n",
       " -0.009718208,\n",
       " -0.002235582,\n",
       " -0.009748207,\n",
       " -0.09278854,\n",
       " 0.037837896,\n",
       " -0.015422697,\n",
       " 0.0162161,\n",
       " -0.0056322655,\n",
       " 0.02393069,\n",
       " 0.04571476,\n",
       " 0.012959352,\n",
       " -0.018765144,\n",
       " -0.0342443,\n",
       " -0.022726433,\n",
       " -0.040489618,\n",
       " -0.01994289,\n",
       " -0.07783773,\n",
       " 0.04576634,\n",
       " -0.023868851,\n",
       " -0.023930328,\n",
       " 0.0111690685,\n",
       " 0.014712,\n",
       " -0.021069577,\n",
       " 0.021227472,\n",
       " 0.0033697959,\n",
       " 0.005478691,\n",
       " -0.015219169,\n",
       " -0.010936828,\n",
       " -0.014078818,\n",
       " 0.039778955,\n",
       " 0.019290825,\n",
       " -0.028922724,\n",
       " -0.018016556,\n",
       " -0.036746036,\n",
       " -0.014878756,\n",
       " 0.014989442,\n",
       " -0.041482273,\n",
       " 0.044242512,\n",
       " 0.055036362,\n",
       " 0.018416803,\n",
       " -0.024312027,\n",
       " -0.025082303,\n",
       " -0.003896047,\n",
       " -0.013693784,\n",
       " 0.058294542,\n",
       " -0.10021392,\n",
       " 0.0029361942,\n",
       " 0.027987612,\n",
       " 0.01923528,\n",
       " -0.025894938,\n",
       " 0.017087987,\n",
       " 0.01516362,\n",
       " -3.9424907e-05,\n",
       " 0.0120801125,\n",
       " 0.05983666,\n",
       " -0.035555433,\n",
       " 0.0028765902,\n",
       " 0.010955967,\n",
       " 0.022815159,\n",
       " -0.025758756,\n",
       " 0.009534163,\n",
       " -0.01569724,\n",
       " -0.10669879,\n",
       " -0.029880255,\n",
       " 0.0016540644,\n",
       " -0.054567628,\n",
       " -0.008736928,\n",
       " 0.00015682675,\n",
       " -0.03955248,\n",
       " -0.004196141,\n",
       " -0.040746253,\n",
       " 0.06934339,\n",
       " -0.0652072,\n",
       " -0.035311952,\n",
       " 0.04558774,\n",
       " 0.008670235,\n",
       " 0.02498005,\n",
       " 0.013850908,\n",
       " -0.028214226,\n",
       " -0.003947297,\n",
       " 0.023957513,\n",
       " 0.007975959,\n",
       " 0.02790059,\n",
       " 0.01940918,\n",
       " -0.03280247,\n",
       " 0.030976813,\n",
       " -0.012157431,\n",
       " -0.06695667,\n",
       " -0.028526112,\n",
       " -0.020364631,\n",
       " -0.0038420074,\n",
       " 0.008281472,\n",
       " 0.02321078,\n",
       " -0.020674307,\n",
       " 0.015456163,\n",
       " -6.728433e-05,\n",
       " -0.0007919428,\n",
       " -0.03794465,\n",
       " 0.061020397,\n",
       " -0.00069387164,\n",
       " 0.0058369306,\n",
       " -0.003967994,\n",
       " 0.006271893,\n",
       " 0.0010884736,\n",
       " 0.0684793,\n",
       " 0.0072071357,\n",
       " -0.005885884,\n",
       " -0.04318258,\n",
       " 0.0542101,\n",
       " -0.023102574,\n",
       " -0.0016019034,\n",
       " 0.007818201,\n",
       " 0.032566566,\n",
       " -0.0029947113,\n",
       " 0.054867957,\n",
       " -0.020259652,\n",
       " -0.06437072,\n",
       " -0.0194635,\n",
       " 0.0034084532,\n",
       " 0.017812904,\n",
       " 0.028821515,\n",
       " -0.047368933,\n",
       " 0.020152653,\n",
       " 0.061266817,\n",
       " -0.012806921,\n",
       " -0.0030200453,\n",
       " 0.065894194,\n",
       " 0.055131286,\n",
       " 0.0072091743,\n",
       " 0.028548546,\n",
       " -0.06423576,\n",
       " 0.02182629,\n",
       " -0.048896898,\n",
       " 0.0032255738,\n",
       " 0.012798411,\n",
       " -0.013370771,\n",
       " 0.031022772,\n",
       " -0.020980896,\n",
       " -0.026319334,\n",
       " -0.018958602,\n",
       " 0.016454317,\n",
       " -0.032661285,\n",
       " 0.02704787,\n",
       " -0.051152132,\n",
       " 0.0693397,\n",
       " 0.021368496,\n",
       " -0.026874049,\n",
       " 0.005640577,\n",
       " 0.027808277,\n",
       " 0.07648806,\n",
       " -0.0037265748,\n",
       " -0.032565042,\n",
       " 0.01774808,\n",
       " -0.030474108,\n",
       " -0.05510326,\n",
       " -0.024666516,\n",
       " 0.0814677,\n",
       " -0.006766482,\n",
       " -0.026629532,\n",
       " -0.06559814,\n",
       " -0.003952712,\n",
       " -0.02573359,\n",
       " 0.021413215,\n",
       " -0.012462403,\n",
       " 0.008995215,\n",
       " 0.008835514,\n",
       " -0.006468027,\n",
       " -0.030513264,\n",
       " 0.067871734,\n",
       " 0.022799179,\n",
       " 0.04949662,\n",
       " 0.052999955,\n",
       " -0.02870435,\n",
       " 0.034419056,\n",
       " -0.05045328,\n",
       " -0.0043545584,\n",
       " -0.010340319,\n",
       " 0.03678884,\n",
       " 0.038892057,\n",
       " 0.019462207,\n",
       " -0.082303286,\n",
       " 0.004822111,\n",
       " 0.011293126,\n",
       " -0.0051773377,\n",
       " -0.019843837,\n",
       " 0.06206615,\n",
       " 0.028643642,\n",
       " -0.08911288,\n",
       " -0.08196645,\n",
       " -0.019334115,\n",
       " -0.008074166,\n",
       " 0.01515049,\n",
       " 0.028377257,\n",
       " -0.001822392,\n",
       " 0.017128324,\n",
       " 0.013427413,\n",
       " -0.029530896,\n",
       " -0.048974834,\n",
       " 0.014295054,\n",
       " -0.023808982,\n",
       " -0.034405902,\n",
       " -0.02540038,\n",
       " -0.04684539,\n",
       " -0.009602635,\n",
       " 0.000936323,\n",
       " -0.030415034,\n",
       " -0.064714774,\n",
       " -0.07143112,\n",
       " -0.033692513,\n",
       " 0.009712644,\n",
       " -0.07775583,\n",
       " 0.03310049,\n",
       " 0.05664606,\n",
       " -0.0068072714,\n",
       " 0.039838117,\n",
       " 0.01954191,\n",
       " 0.018471401,\n",
       " 0.03229613,\n",
       " 0.011890665,\n",
       " 0.01872409,\n",
       " 0.023821956,\n",
       " -0.014033455,\n",
       " -0.03889431,\n",
       " -0.010944821,\n",
       " 0.005496459,\n",
       " 0.048139818,\n",
       " 0.023888674,\n",
       " 0.0007157945,\n",
       " -0.033608593,\n",
       " -0.057029944,\n",
       " 0.007018293,\n",
       " -0.011153769,\n",
       " -0.017511178,\n",
       " 0.07684766,\n",
       " 0.006502155,\n",
       " 0.029135508,\n",
       " -0.017689401,\n",
       " -0.019108204,\n",
       " -0.0019254591,\n",
       " 0.042225603,\n",
       " -0.026789108,\n",
       " -0.07679128,\n",
       " -0.02459347,\n",
       " 0.043536406,\n",
       " 0.036564868,\n",
       " 0.0040566586,\n",
       " 0.032375004,\n",
       " 0.022406014,\n",
       " 0.030956889,\n",
       " 0.053786006,\n",
       " 0.013066771,\n",
       " -0.03500168,\n",
       " -0.017186835,\n",
       " 0.03595448,\n",
       " 0.0039045298,\n",
       " -0.07080411,\n",
       " 0.015853249,\n",
       " 0.026626416,\n",
       " -0.020210162,\n",
       " 0.055352587,\n",
       " 0.03876443,\n",
       " 0.038574673,\n",
       " 0.014929438,\n",
       " -0.0069062677,\n",
       " -0.05856704,\n",
       " 0.07191228,\n",
       " -0.037036296,\n",
       " 0.017161489,\n",
       " -0.018750755,\n",
       " -0.015499783,\n",
       " 0.085961334,\n",
       " -0.008817073,\n",
       " -0.034059335,\n",
       " 0.02162897,\n",
       " -0.046303682,\n",
       " 0.084854014,\n",
       " 0.023842977,\n",
       " 0.031723797,\n",
       " -0.003653463,\n",
       " -0.052499156,\n",
       " -0.032130204,\n",
       " 0.013451527,\n",
       " 0.014359322,\n",
       " 0.035654224,\n",
       " 0.017325768,\n",
       " -0.022298757,\n",
       " 0.008471368,\n",
       " -0.034369618,\n",
       " 0.025300728,\n",
       " -0.063756384,\n",
       " -0.024632473,\n",
       " 0.0141245695,\n",
       " -0.048312984,\n",
       " 0.012400936,\n",
       " 0.03538527,\n",
       " -0.0009061925,\n",
       " -0.0013517677,\n",
       " -0.016639275,\n",
       " -0.009296433,\n",
       " 0.010673586,\n",
       " -0.03981289,\n",
       " 0.013041012,\n",
       " 0.031623904,\n",
       " -0.02216119,\n",
       " 0.020661386,\n",
       " -0.0023918964,\n",
       " -0.0061003747,\n",
       " 0.022709038]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "text = \"진희는 강아지를 키우고 있습니다. 진희가 키우고 있는 동물은?\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "text_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 검색기(RetrievalQA) 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "db = FAISS.from_documents(document, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeongcheol/anaconda3/envs/kaggle/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '마을 무덤에 있던 남자를 죽인 사람은 누구니?',\n",
       " 'result': '마을 무덤에 있던 남자를 죽인 사람은 이야기에서 언급되지 않았습니다.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0,\n",
    "#            model_name=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0)\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    ")\n",
    "query = \"마을 무덤에 있던 남자를 죽인 사람은 누구니?\"\n",
    "result = qa({\"query\": query})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeongcheol/anaconda3/envs/kaggle/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "/Users/yeongcheol/anaconda3/envs/kaggle/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'서울'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0,\n",
    "                #  model_name=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"{country}의 수도는 어디야?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt) # prompt와 모델을 체인으로 연결\n",
    "chain.run(\"대한민국\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequentialChain으로 여러 체인 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '\\nOne limitation of LLMs is their lack of contextual information (e.g., access to some specific documents or emails). You can combat this by giving LLMs access to the specific external data.\\nFor this, you first need to load the external data with a document loader. LangChain provides a variety of loaders for different types of documents ranging from PDFs and emails to websites and YouTube videos.',\n",
       " 'translation': 'LLM의 한 가지 한계는 맥락 정보가 부족하다는 것입니다(예: 특정 문서나 이메일 접근). LLM에 특정 외부 데이터에 대한 액세스 권한을 부여하여 이를 해결할 수 있습니다. 이를 위해서는 먼저 문서 로더를 사용하여 외부 데이터를 로드해야 합니다. LangChain은 PDF, 이메일, 웹사이트, YouTube 동영상 등 다양한 유형의 문서에 대한 다양한 로더를 제공합니다.',\n",
       " 'summary': 'LLM의 맥락 정보 부족 한계는 LangChain의 문서 로더를 사용하여 외부 데이터에 액세스 권한을 부여하여 해결할 수 있습니다.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=[\"sentence\"],\n",
    "    template=\"다음 문장을 한글로 번역하세요.\\n\\n{sentence}\",\n",
    ")\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1, output_key=\"translation\")\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(\n",
    "    \"다음 문장을 한 문장으로 요약하세요.\\n\\n{translation}\", # chain1의 output_key\n",
    ")\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2, output_key=\"summary\")\n",
    "\n",
    "# chain1 + chain2\n",
    "all_chains = SequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    input_variables=[\"sentence\"],\n",
    "    output_variables=[\"translation\", \"summary\"],\n",
    ")\n",
    "sentence=\"\"\"\n",
    "One limitation of LLMs is their lack of contextual information (e.g., access to some specific documents or emails). You can combat this by giving LLMs access to the specific external data.\n",
    "For this, you first need to load the external data with a document loader. LangChain provides a variety of loaders for different types of documents ranging from PDFs and emails to websites and YouTube videos.\"\"\"\n",
    "result = all_chains(sentence)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메모리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Chris has a dog.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Chris has a dog.\n",
      "AI: Chris has a dog named Buddy. Buddy is a 3-year-old golden retriever. He is very friendly and loves to play fetch. Chris and Buddy often go for walks in the park.\n",
      "Human: Emma has 2 cats.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Chris has a dog.\n",
      "AI: Chris has a dog named Buddy. Buddy is a 3-year-old golden retriever. He is very friendly and loves to play fetch. Chris and Buddy often go for walks in the park.\n",
      "Human: Emma has 2 cats.\n",
      "AI: Emma has 2 cats named Mittens and Whiskers. Mittens is a 5-year-old calico cat. She is very shy and loves to cuddle. Whiskers is a 2-year-old tabby cat. He is very playful and loves to chase toys. Emma and her cats often play together in the living room.\n",
      "Human: How many animals do Chris and Emma have?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chris and Emma have 3 animals. Chris has a dog named Buddy, and Emma has 2 cats named Mittens and Whiskers.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory\n",
    "from langchain import ConversationChain\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0,\n",
    "#                  model_name=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "# conversation.predict(input=\"진희는 강아지를 한마리 키우고 있습니다.\")\n",
    "# conversation.predict(input=\"영수는 고양이를 두마리 키우고 있습니다.\")\n",
    "# conversation.predict(input=\"진희와 영수가 키우는 동물은 총 몇마리?\")\n",
    "\n",
    "conversation.predict(input=\"Chris has a dog.\")\n",
    "conversation.predict(input=\"Emma has 2 cats.\")\n",
    "conversation.predict(input=\"How many animals do Chris and Emma have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 에이전트/툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
      "Action Input: Ed Sheeran\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Ed Sheeran\n",
      "Summary: Edward Christopher Sheeran  ( SHEER-ən; born 17 February 1991) is an English singer-songwriter. Born in Halifax, West Yorkshire, and raised in Framlingham, Suffolk, he began writing songs around the age of eleven. In early 2011, Sheeran independently released the extended play No. 5 Collaborations Project. He signed with Asylum Records the same year.\n",
      "Sheeran's debut album, + (\"Plus\"), was released in September 2011 and topped the UK Albums Chart. It contained his first hit single \"The A Team\". In 2012, Sheeran won the Brit Awards for Best British Male Solo Artist and British Breakthrough Act. Sheeran's second studio album, × (\"Multiply\"), topped charts around the world upon its release in June 2014. It was named the second-best-selling album worldwide of 2015. In the same year, × won Album of the Year at the 2015 Brit Awards, and he received the Ivor Novello Award for Songwriter of the Year from the British Academy of Songwriters, Composers and Authors. A single from ×, \"Thinking Out Loud\", earned him the 2016 Grammy Awards for Song of the Year and Best Pop Solo Performance.\n",
      "Sheeran's third album, ÷ (\"Divide\"), was released in March 2017, and was the best-selling album worldwide of 2017. The first two singles from the album, \"Shape of You\" and \"Castle on the Hill\", broke records in a number of countries by debuting in the top two positions of the charts. He also became the first artist to have two songs debut in the US top 10 in the same week. By March 2017, Sheeran had accumulated ten top-10 singles from ÷ on the UK Singles Chart, breaking the record for most top-10 UK singles from one album. His fourth single from ÷, \"Perfect\", reached number one in the US, Australia, and the UK, where it became the Christmas number one in 2017. The world's best-selling artist of 2017, he was named the Global Recording Artist of the Year. Released in 2019, his fourth overall and first collaborative album, No.6 Collaborations Project, debuted at number one in most major markets, and spawned three UK number one singles, \"I Don't Care\", \"Beautiful People\", and \"Take Me Back to London\". His fifth studio album, = (\"Equals\"), topped the charts in most major markets in 2021. His sixth album, - (\"Subtract\"), was released on 5 May 2023, while his seventh album, Autumn Variations, was released on 29 September 2023 under his own record label, Gingerbread Man Records.\n",
      "Sheeran has sold more than 150 million records worldwide, making him one of the world's best-selling music artists. He has 101 million RIAA-certified units in the US, and two of his albums are in the list of the best-selling albums in UK chart history. In December 2019, the Official Charts Company named him artist of the decade, with the most combined success in the UK album and singles charts in the 2010s. As of April 2022, he is the most followed artist on Spotify. Beginning in March 2017, his ÷ Tour became the highest-grossing of all time in August 2019. An alumnus of the National Youth Theatre in London, Sheeran's acting roles include appearing in the 2019 film Yesterday, playing himself.\n",
      "\n",
      "Page: Ed Sheeran discography\n",
      "Summary: The discography of English singer-songwriter Ed Sheeran consists of seven studio albums, seventeen extended plays, one video album, sixty-five singles (including twenty-eight as a featured artist), eight promotional singles, one box set, and seventy-one music videos. As of October 2021, Sheeran has sold over 150 million records worldwide, making him one of the best-selling music artists in history. According to RIAA, Sheeran is the 13th best-selling digital singles artist in the United States with certified sales of 80.5 million.\n",
      "Originally an indie artist selling music independently on his own label starting in 2005, Sheeran released nine EPs, steadily gaining public and critical acclaim, resulting in his signing to Atlantic Records in January 2011. Five months later, Sheeran released his first single, \"The A Team\", on 12 June 2011. It \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Calculator\n",
      "Action Input: 2024 - 1991\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 33\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Ed Sheeran was born in 1991 and will be 33 years old in 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ed Sheeran was born in 1991 and will be 33 years old in 2024.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(temperature=0,\n",
    "#                  model_name=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0)\n",
    "\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm,\n",
    "                 agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                 description=\"계산이 필요할 때 사용\",\n",
    "                 verbose=True)\n",
    "# agent.run(\"에드 시런이 태어난 해는? 2024년도 기준으로 에드 시런은 몇 살?\")\n",
    "agent.run(\"What year was Ed Sheeran born? And how old is he in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
